from config.chatty_chain_constructor import horowag_conversation_chain, qwen_translation_chain
from config.chatty_model_rebuilder import Qwen_Assistant, Horowag
from langchain.prompts import PromptTemplate
import subprocess
import gradio as gr
import sys
import os

__file__ = "/root/Chatty_Horo_Voich/Voice/"

# Qwen æ¨¡å‹åˆå§‹åŒ–
Qwen_model = Qwen_Assistant(
    model_path="/root/Chatty_Horo_Voich/T_Model/Qwen1_5_4b_Chat_AWQ",
    top_p=0.25,
    max_token=128, 
    temperature=0.1
)

# æ„å»ºç¿»è¯‘é“¾
qwen_translation_chain = qwen_translation_chain(Qwen_model)

# å®šä¹‰éŸ³é¢‘æ„å»ºå‡½æ•°
def voice_builder(context: str):
    # å®šä¹‰ API å‚æ•°
    program = "/root/Chatty_Horo_Voich/VITS-fast-fine-tuning/cmd_inference.py"
    api_param_args_1 = "-m" 
    api_param_conf_1 = "/root/Chatty_Horo_Voich/V_Model/Test/module/G_10000R.pth"
    api_param_args_2 = "-c" 
    api_param_conf_2 = "/root/Chatty_Horo_Voich/V_Model/Test/config/config.json"
    api_param_args_3 = "-o" 
    api_param_conf_3 = "/root/Chatty_Horo_Voich/Voice/"
    api_param_args_4 = "-l" 
    api_param_conf_4 = "æ—¥æœ¬èª"
    api_param_args_5 = "-t" 
    api_param_conf_5 = context
    api_param_args_6 = "-s"
    api_param_conf_6 = "æ—¥è¯­åŒ—æ–—ï¼ˆå°æ¸…æ°´äºšç¾ï¼‰"
    api_param_args_7 = "-ls"
    api_param_conf_7 = "0.85"
    
    api_pt = [api_param_args_1, api_param_conf_1, 
              api_param_args_2, api_param_conf_2,
              api_param_args_3, api_param_conf_3,
              api_param_args_4, api_param_conf_4,
              api_param_args_5, api_param_conf_5,
              api_param_args_6, api_param_conf_6,
              api_param_args_7, api_param_conf_7]
    # æ‰§è¡Œå¦ä¸€ä¸ª Python æ–‡ä»¶ï¼Œå¹¶ä¼ é€’å‚æ•°
    subprocess.run([sys.executable, program] + api_pt)

# æ„é€ æ¨¡å‹é“¾çš„å¯¹è±¡
class Chatty_Horo_Chain:
    """
        talk_chain + chatty_chatty + Voicy_Voicy
    """
    def __init__(self, model_path, qwen_translation_chain):
        self.talk_chain = horowag_conversation_chain(
            llm=Horowag(
                model_path=model_path,
                max_token=256,
                temperature=0.75,
                top_p=0.95
            )
        )
        # Chain
        self.qwen_translation_chain = qwen_translation_chain
        # Global
        self.ans = None

    def voicy_voicy(self, question: str, chat_history: list = []):
        """
            ç”¨äºèŠå¤© + å£°éŸ³
        """
        if question == None or len(question) < 1:
            return "", chat_history
        try:
            self.ans = self.talk_chain.predict(input=question)
            
            # ç¿»è¯‘éŸ³é¢‘ç»“æœ
            translate_ans = self.qwen_translation_chain.run(
                source_language='ä¸­æ–‡', 
                target_language='æ—¥æœ¬èª', 
                text=self.ans
            )
            
            print("ç¿»è¯‘ç»“æœæ˜¯ï¼š", translate_ans)
            # è½¬åŒ–éŸ³é¢‘æ–‡ä»¶(æ—¶åº)
            voice_builder(context=translate_ans)
            
            # èŠå¤©å‡½æ•°
            chat_history.append(
                (question, self.ans)
            )
            
            return "", chat_history
        except Exception as e:
            return e, chat_history

    # Normal Chat
    def chatty_chatty(self, question: str, chat_history: list = []):
        """
            ç”¨äºèŠå¤©
        """
        if question == None or len(question) < 1:
            return "", chat_history
        try:
            self.ans = self.talk_chain.predict(input=question)

            # èŠå¤©å‡½æ•°
            chat_history.append(
                (question, self.ans)
            )
            
            return "", chat_history
        except Exception as e:
            return e, chat_history    

    # éŸ³é¢‘æ¨¡å—
    def txt_to_audio(self):
        """
            ç”¨äºéŸ³é¢‘è½¬åŒ–
        """
        # è·¯å¾„
        return os.path.join(os.path.dirname(__file__), "output.wav")


# æ„å»ºå¯¹è¯æ¨¡å¼
Chatty_Horo_Chain = Chatty_Horo_Chain(
    model_path="/root/horowag/config/work_dirs/hf_merge",
    qwen_translation_chain=qwen_translation_chain
)

# æ„å»º gradio å¯¹è¯
block_1 = gr.Blocks()
with block_1 as demo_1:
    with gr.Row(equal_height=True):
        with gr.Column(scale=15):
            gr.Markdown(
                """
                <h1>
                <center>ğŸVoicy-HoroğŸ</center>
                </h1>
                <center>ğŸooO è¯­éŸ³ + æ–‡æœ¬ OooğŸ</center>
                """)

    with gr.Row(equal_height=True):
        with gr.Column(scale=6):
            chatbot = gr.Chatbot(height=695, show_copy_button=True)
        with gr.Column(scale=2):
            audiobot = gr.Audio(
                type="filepath",
                interactive=False,
                autoplay=False
            )
            with gr.Row():      
                gr.Image(
                    value="/root/Chatty_Horo_Voich/72f177ca7f42b5adb48b8edfa7e3bed.jpg",
                    interactive=False,
                    height="auto",
                    label="Horo",
                    type="pil"
                )

    with gr.Row(equal_height=True):
        with gr.Column(scale=8):
            # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œç”¨äºè¾“å…¥ promptã€‚
            msg = gr.Textbox(label="åœ¨æ­¤è¾“å…¥èŠå¤©å†…å®¹...")
            with gr.Row():
                # åˆ›å»ºæäº¤æŒ‰é’®ã€‚
                chatty_btn = gr.Button("Chat")
            with gr.Row():
                # åˆ›å»ºä¸€ä¸ªæ¸…é™¤æŒ‰é’®ï¼Œç”¨äºæ¸…é™¤èŠå¤©æœºå™¨äººç»„ä»¶çš„å†…å®¹ã€‚
                clear = gr.ClearButton(
                    components=[chatbot], value="Clear console")

        # è®¾ç½®æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ã€‚å½“ç‚¹å‡»æ—¶ï¼Œè°ƒç”¨ä¸Šé¢å®šä¹‰çš„å‡½æ•°ï¼Œå¹¶ä¼ å…¥ç”¨æˆ·çš„æ¶ˆæ¯å’ŒèŠå¤©å†å²è®°å½•ï¼Œç„¶åæ›´æ–°æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶ã€‚
        chatty_btn.click(
            fn=Chatty_Horo_Chain.voicy_voicy,
            inputs=[msg, chatbot],
            outputs=[msg, chatbot],
        )

        chatbot.change(fn=Chatty_Horo_Chain.txt_to_audio,
                       inputs=None,
                       outputs=[audiobot])

    gr.Markdown("""ğŸä¸èµ«èé—²èŠæ—¶çš„æç¤ºğŸï¼š
    <br>
    1. ğŸ¯è¯­éŸ³ç‰ˆå› ä¸ºç®—åŠ›é™åˆ¶ï¼Œè¿ç®—æ—¶é—´è¾ƒé•¿(>=20s, <=100s)ï¼Œè¯·è€å¿ƒç­‰å¾…ğŸ¯
    2. âœ¨å¦‚æœå¸Œæœ›èƒ½å¤Ÿä¸è´¤ç‹¼èµ«èå¿«é€Ÿæ²Ÿé€šï¼Œå»ºè®®ä½¿ç”¨ Chatty-Chatty ç‰ˆæœ¬(å·¦ä¸Šè§’ Tab)âœ¨
    3. ğŸŒ ç‰ˆæœ¬è™½ç„¶æœ‰ä¸€å®šé²æ£’æ€§ï¼Œä½†æ˜¯é™äºä¸ªäººæŠ€æœ¯ï¼Œè¯·å°½å¯èƒ½ä½¿ç”¨ä¸­æ–‡ä¸”å‡å°‘é”™å­—ğŸŒ 
    <br>
    """)

# threads to consume the request
gr.close_all()

# æ„å»º gradio å¯¹è¯
block_2 = gr.Blocks()
with block_2 as demo_2:
    with gr.Row(equal_height=True):
        with gr.Column(scale=15):
            gr.Markdown(
                """
                <h1>
                <center>ğŸChatty-HoroğŸ</center>
                </h1>
                <center>ğŸooO æ–‡æœ¬ç”Ÿæˆ OooğŸ</center>
                """)

    with gr.Row(equal_height=True):
        with gr.Column(scale=6):
            chatbot = gr.Chatbot(height=450, show_copy_button=True)

    with gr.Row(equal_height=True):
        with gr.Column(scale=8):
            # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œç”¨äºè¾“å…¥ promptã€‚
            msg = gr.Textbox(label="åœ¨æ­¤è¾“å…¥èŠå¤©å†…å®¹...")
            with gr.Row():
                # åˆ›å»ºæäº¤æŒ‰é’®ã€‚
                chatty_btn = gr.Button("Chat")
            with gr.Row():
                # åˆ›å»ºä¸€ä¸ªæ¸…é™¤æŒ‰é’®ï¼Œç”¨äºæ¸…é™¤èŠå¤©æœºå™¨äººç»„ä»¶çš„å†…å®¹ã€‚
                clear = gr.ClearButton(
                    components=[chatbot], value="Clear console")

        # è®¾ç½®æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ã€‚å½“ç‚¹å‡»æ—¶ï¼Œè°ƒç”¨ä¸Šé¢å®šä¹‰çš„å‡½æ•°ï¼Œå¹¶ä¼ å…¥ç”¨æˆ·çš„æ¶ˆæ¯å’ŒèŠå¤©å†å²è®°å½•ï¼Œç„¶åæ›´æ–°æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶ã€‚
        chatty_btn.click(
            fn=Chatty_Horo_Chain.chatty_chatty,
            inputs=[msg, chatbot],
            outputs=[msg, chatbot],
        )

    gr.Markdown("""ğŸä¸èµ«èé—²èŠæ—¶çš„æç¤ºğŸï¼š
    <br>
    1. ğŸ¯è¯­éŸ³ç‰ˆå› ä¸ºç®—åŠ›é™åˆ¶ï¼Œè¿ç®—æ—¶é—´è¾ƒé•¿(>=20s, <=100s)ï¼Œè¯·è€å¿ƒç­‰å¾…ğŸ¯
    2. âœ¨å¦‚æœå¸Œæœ›èƒ½å¤Ÿä¸è´¤ç‹¼èµ«èå¿«é€Ÿæ²Ÿé€šï¼Œå»ºè®®ä½¿ç”¨ Chatty-Chatty ç‰ˆæœ¬(å·¦ä¸Šè§’ Tab)âœ¨
    3. ğŸŒ ç‰ˆæœ¬è™½ç„¶æœ‰ä¸€å®šé²æ£’æ€§ï¼Œä½†æ˜¯é™äºä¸ªäººæŠ€æœ¯ï¼Œè¯·å°½å¯èƒ½ä½¿ç”¨ä¸­æ–‡ä¸”å‡å°‘é”™å­—ğŸŒ 
    <br>
    """)

# threads to consume the request
demo = gr.TabbedInterface([block_1, block_2], ["Voicy_Voicy", "Chatty_Chatty"])
# threads to consume the request
gr.close_all()
# é’ˆå¯¹ Gradioçš„ç¾åŒ–

# å¯åŠ¨æ–°çš„ Gradio åº”ç”¨ï¼Œè®¾ç½®åˆ†äº«åŠŸèƒ½ä¸º Trueï¼Œå¹¶ä½¿ç”¨ç¯å¢ƒå˜é‡ PORT1 æŒ‡å®šæœåŠ¡å™¨ç«¯å£ã€‚
# demo.launch(share=True, server_port=int(os.environ['PORT1']))
# ç›´æ¥å¯åŠ¨
demo.launch(share=True, server_port=7860)
